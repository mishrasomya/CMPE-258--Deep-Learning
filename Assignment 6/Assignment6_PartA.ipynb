{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6_PartA.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwFXAck6xXCp"
      },
      "source": [
        "## Assignemnt 6- Part A: Autograd Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZEwErw4xr8N"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from scipy.special import softmax\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JReJPJC4jAZT"
      },
      "source": [
        "#Define Autograd class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H0PdX0exud0"
      },
      "source": [
        "# Define the class Tensor\n",
        "class Tensor (object):\n",
        "    def __init__(self,data,\n",
        "                 autograd=False,\n",
        "                 creators=None,\n",
        "                 creation_op=None,\n",
        "                 id=None):\n",
        "        \n",
        "        self.data = np.array(data)\n",
        "        self.autograd = autograd\n",
        "        self.grad = None\n",
        "\n",
        "        if(id is None):\n",
        "            self.id = np.random.randint(0,1000000000)\n",
        "        else:\n",
        "            self.id = id\n",
        "        \n",
        "        self.creators = creators\n",
        "        self.creation_op = creation_op\n",
        "        self.children = {}\n",
        "        \n",
        "        if(creators is not None):\n",
        "            for c in creators:\n",
        "                if(self.id not in c.children):\n",
        "                    c.children[self.id] = 1\n",
        "                else:\n",
        "                    c.children[self.id] += 1\n",
        "\n",
        "    def all_children_grads_accounted_for(self):\n",
        "        for id,cnt in self.children.items():\n",
        "            if(cnt != 0):\n",
        "                return False\n",
        "        return True \n",
        "        \n",
        "    def backward(self,grad=None, grad_origin=None):\n",
        "        if(self.autograd):\n",
        " \n",
        "            if(grad is None):\n",
        "                grad = FloatTensor(np.ones_like(self.data))\n",
        "\n",
        "            if(grad_origin is not None):\n",
        "                if(self.children[grad_origin.id] == 0):\n",
        "                    return\n",
        "                    print(self.id)\n",
        "                    print(self.creation_op)\n",
        "                    print(len(self.creators))\n",
        "                    for c in self.creators:\n",
        "                        print(c.creation_op)\n",
        "                    raise Exception(\"cannot backprop more than once\")\n",
        "                else:\n",
        "                    self.children[grad_origin.id] -= 1\n",
        "\n",
        "            if(self.grad is None):\n",
        "                self.grad = grad\n",
        "            else:\n",
        "                self.grad += grad\n",
        "            \n",
        "            # grads must not have grads of their own\n",
        "            assert grad.autograd == False\n",
        "            \n",
        "            # only continue backpropping if there's something to\n",
        "            # backprop into and if all gradients (from children)\n",
        "            # are accounted for override waiting for children if\n",
        "            # \"backprop\" was called on this variable directly\n",
        "            if(self.creators is not None and \n",
        "               (self.all_children_grads_accounted_for() or \n",
        "                grad_origin is None)):\n",
        "\n",
        "                if(self.creation_op == \"add\"):\n",
        "                    self.creators[0].backward(self.grad, self)\n",
        "                    self.creators[1].backward(self.grad, self)\n",
        "                    \n",
        "                if(self.creation_op == \"sub\"):\n",
        "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
        "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
        "\n",
        "                if(self.creation_op == \"mul\"):\n",
        "                    new = self.grad * self.creators[1]\n",
        "                    self.creators[0].backward(new , self)\n",
        "                    new = self.grad * self.creators[0]\n",
        "                    self.creators[1].backward(new, self)                    \n",
        "                    \n",
        "                if(self.creation_op == \"mm\"):\n",
        "                    c0 = self.creators[0]\n",
        "                    c1 = self.creators[1]\n",
        "                    new = self.grad.mm(c1.transpose())\n",
        "                    c0.backward(new)\n",
        "                    new = self.grad.transpose().mm(c0).transpose()\n",
        "                    c1.backward(new)\n",
        "                    \n",
        "                if(self.creation_op == \"transpose\"):\n",
        "                    self.creators[0].backward(self.grad.transpose())\n",
        "\n",
        "                if(\"sum\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.expand(dim,\n",
        "                                                               self.creators[0].data.shape[dim]))\n",
        "\n",
        "                if(\"expand\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.sum(dim))\n",
        "                    \n",
        "                if(self.creation_op == \"neg\"):\n",
        "                    self.creators[0].backward(self.grad.__neg__())\n",
        "                    \n",
        "                if(self.creation_op == \"sigmoid\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
        "                \n",
        "                if(self.creation_op == \"tanh\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
        "                \n",
        "                if self.creation_op == \"softmax\":\n",
        "                    self.creators[0].backward(self.grad)\n",
        "\n",
        "                if(self.creation_op == \"index_select\"):\n",
        "                    new_grad = np.zeros_like(self.creators[0].data)\n",
        "                    indices_ = self.index_select_indices.data.flatten()\n",
        "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
        "                    for i in range(len(indices_)):\n",
        "                        new_grad[indices_[i]] += grad_[i]\n",
        "                    self.creators[0].backward(Tensor(new_grad))\n",
        "                    \n",
        "                if(self.creation_op == \"cross_entropy\"):\n",
        "                    dx = self.softmax_output - self.target_dist\n",
        "                    self.creators[0].backward(Tensor(dx))\n",
        "                    \n",
        "    def __add__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data + other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"add\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __neg__(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data * -1,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"neg\")\n",
        "        return Tensor(self.data * -1)\n",
        "    \n",
        "    def __sub__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data - other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"sub\")\n",
        "        return Tensor(self.data - other.data)\n",
        "    \n",
        "    def __mul__(self, other):\n",
        "        if(self.autograd and other.autograd):\n",
        "            return Tensor(self.data * other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"mul\")\n",
        "        return Tensor(self.data * other.data)    \n",
        "\n",
        "    def sum(self, dim):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.sum(dim),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sum_\"+str(dim))\n",
        "        return Tensor(self.data.sum(dim))\n",
        "    \n",
        "    def expand(self, dim,copies):\n",
        "        trans_cmd = list(range(0,len(self.data.shape)))\n",
        "        trans_cmd.insert(dim,len(self.data.shape))\n",
        "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
        "        \n",
        "        if(self.autograd):\n",
        "            return Tensor(new_data,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"expand_\"+str(dim))\n",
        "        return Tensor(new_data)\n",
        "    \n",
        "    def transpose(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.transpose(),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"transpose\")\n",
        "        \n",
        "        return Tensor(self.data.transpose())\n",
        "    \n",
        "    def mm(self, x):\n",
        "        if(self.autograd):\n",
        "            return Tensor(self.data.dot(x.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self,x],\n",
        "                          creation_op=\"mm\")\n",
        "        return Tensor(self.data.dot(x.data))\n",
        "    \n",
        "    def sigmoid(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(1 / (1 + np.exp(-self.data)),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sigmoid\")\n",
        "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
        "\n",
        "    def tanh(self):\n",
        "        if(self.autograd):\n",
        "            return Tensor(np.tanh(self.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"tanh\")\n",
        "        return Tensor(np.tanh(self.data))\n",
        "    \n",
        "    def index_select(self, indices):\n",
        "\n",
        "        if(self.autograd):\n",
        "            new = Tensor(self.data[indices.data],\n",
        "                         autograd=True,\n",
        "                         creators=[self],\n",
        "                         creation_op=\"index_select\")\n",
        "            new.index_select_indices = indices\n",
        "            return new\n",
        "        return Tensor(self.data[indices.data])\n",
        "    \n",
        "    def shape(self):\n",
        "      return self.data.shape\n",
        "    \n",
        "    def softmax(self):\n",
        "        x = self.data - self.data.max(axis=1, keepdims=True)\n",
        "        y = np.exp(x)\n",
        "        v = y / y.sum(axis=1, keepdims=True)\n",
        "\n",
        "        if(self.autograd):\n",
        "            return Tensor(v,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"softmax\")\n",
        "        return Tensor(v)\n",
        "\n",
        "    def cross_entropy(self, target_indices):\n",
        "        temp = np.exp(self.data)\n",
        "        softmax_output = temp / np.sum(temp,\n",
        "                                       axis=len(self.data.shape)-1,\n",
        "                                       keepdims=True)\n",
        "        \n",
        "        t = target_indices.data.flatten()\n",
        "        p = softmax_output.reshape(len(t),-1)\n",
        "        target_dist = np.eye(p.shape[1])[t]\n",
        "        loss = -(np.log(p) * (target_dist)).sum(1).mean()\n",
        "    \n",
        "        if(self.autograd):\n",
        "            out = Tensor(loss,\n",
        "                         autograd=True,\n",
        "                         creators=[self],\n",
        "                         creation_op=\"cross_entropy\")\n",
        "            out.softmax_output = softmax_output\n",
        "            out.target_dist = target_dist\n",
        "            return out\n",
        "\n",
        "        return Tensor(loss)\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "    \n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObOy8jHGhoj6"
      },
      "source": [
        "#Unit Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHety9cgjJ5W"
      },
      "source": [
        "##Add"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcOt0KRfz390"
      },
      "source": [
        "def add():\n",
        "  a = Tensor([1, 2, 3, 4, 5], autograd=True)\n",
        "  b = Tensor([2, 2, 2, 2, 2], autograd=True)\n",
        "\n",
        "  c = a + b\n",
        "  c.backward(Tensor(np.array([1, 1, 1, 1, 1])))\n",
        "\n",
        "  np.testing.assert_array_equal(a.grad.data, [1, 1, 1, 1, 1])\n",
        "  np.testing.assert_array_equal(b.grad.data, [1, 1, 1, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwj4FPp4jLj5"
      },
      "source": [
        "##Subtraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFUYRtAb0QFd"
      },
      "source": [
        "def sub():\n",
        "  a = Tensor([1, 2, 3, 4, 5], autograd=True)\n",
        "  b = Tensor([2, 2, 2, 2, 2], autograd=True)\n",
        "\n",
        "  c = a - b\n",
        "  c.backward(Tensor(np.array([1, 1, 1, 1, 1])))\n",
        "  \n",
        "  np.testing.assert_array_equal(a.grad.data, [1, 1, 1, 1, 1])\n",
        "  np.testing.assert_array_equal(b.grad.data, [-1, -1, -1, -1, -1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci8UeSZFjNeD"
      },
      "source": [
        "##Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3HlXT1J1ONf"
      },
      "source": [
        "def mul():\n",
        "  a = Tensor([1, 2, 3, 4, 5], autograd=True)\n",
        "  b = Tensor([2, 2, 2, 2, 2], autograd=True)\n",
        "\n",
        "  e = a * b\n",
        "  e.backward(Tensor(np.array([1, 1, 1, 1, 1])))\n",
        "\n",
        "  np.testing.assert_array_equal(a.grad.data, [2, 2, 2, 2, 2])\n",
        "  np.testing.assert_array_equal(b.grad.data, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rCp5gYnhrYt"
      },
      "source": [
        "#Loading MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89FRG-vx4WKi"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import itertools\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDf_O9KQlzHu"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MQ1SddhkyL7"
      },
      "source": [
        "#Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYyDj85ViIg1"
      },
      "source": [
        "def visualize__dataset(dataset, N, name):\n",
        "  print(\"Visualizing the \" + name + \" dataset.\")\n",
        "  fig = plt.figure(figsize=plt.figaspect(0.3))\n",
        "\n",
        "  for image in range(0, N):\n",
        "    ax = fig.add_subplot(1, 10, image+1)\n",
        "    ax.imshow(dataset[image], cmap='Accent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "BDMRcZRiiYYu",
        "outputId": "c6d5077f-b535-45df-9aae-9ccb0ecec0a5"
      },
      "source": [
        "n = 10\n",
        "visualize__dataset(X_train, n, \"train\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualizing the train dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 960x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjo3XMcbmVmw"
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhgSiX8YibcF"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28*28) / 255.\n",
        "X_test = X_test.reshape(X_test.shape[0], 28*28) / 255.\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfij0-pck8bE"
      },
      "source": [
        "X_train = X_train[:10]\n",
        "y_train = y_train[:10]\n",
        "X_test = X_test[:100]\n",
        "y_test = y_test[:100]\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giXcIXy0lL71"
      },
      "source": [
        "#Train Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STkoPa7blK3N",
        "outputId": "a591bc6c-1430-40c7-ff89-225a4451385f"
      },
      "source": [
        "data = Tensor(X_train, autograd=True)\n",
        "expected = Tensor(y_train, autograd=True)\n",
        "\n",
        "weights = []\n",
        "weights.append(Tensor(np.random.rand(input_dim, 64), autograd=True))\n",
        "weights.append(Tensor(np.random.rand(64, 10), autograd=True))\n",
        "learning_rate = 0.0001\n",
        " \n",
        "for i in range(10):\n",
        "\n",
        "  predicted = data.mm(weights[0]).mm(weights[1]).softmax()\n",
        "  loss = ((predicted - expected) * (predicted - expected)).sum(0)\n",
        "  loss.backward(Tensor(np.ones_like(loss.data)))\n",
        "  for wts in weights:\n",
        "    wts.data -= wts.grad.data*learning_rate\n",
        "    wts.grad.data = wts.grad.data*0\n",
        "    print(np.mean(loss.data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.599465657533295\n",
            "1.599465657533295\n",
            "1.6541062867850265\n",
            "1.6541062867850265\n",
            "1.7765837817684642\n",
            "1.7765837817684642\n",
            "1.7999999999157268\n",
            "1.7999999999157268\n",
            "1.4000000000030013\n",
            "1.4000000000030013\n",
            "1.7812403419274634\n",
            "1.7812403419274634\n",
            "1.7999577946503098\n",
            "1.7999577946503098\n",
            "1.6\n",
            "1.6\n",
            "1.7203136364865\n",
            "1.7203136364865\n",
            "1.6404982125161751\n",
            "1.6404982125161751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe135iWtlO8u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}